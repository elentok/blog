<html><head><title>@elentok - </title><style type="text/css">body {
  font-family: sans-serif;
  background: #242424;
  color: #e9e9e9;
  font-size: 18px;
  line-height: 1.5;
}

pre, code {
  font-family: 'Source Code Pro';
}

pre {
  padding: 15px;
  background-color: #121212;
  border-radius: 5px;
  line-height: 1.3;
}

a, a:visited {
  color: #98adec;
}

.e-page {
  margin: auto;
  max-width: 700px;
}</style></head><body><div class="e-page"><a class="e-header" href="/"><div class="e-header__avatar"><div class="e-avatar"></div></div><h1>Elentok's Blog</h1></a><h2>ActiveRecord+PostgreSQL mass-insertion benchmarks</h2><div><p>In the past couple of weeks I&#39;ve been researching databases and optimization techniques and I just wanted to share something I discovered.</p>
<p>I&#39;m using:</p>
<ul>
<li>Linux Mint 13</li>
<li>PostgreSQL 9.1 (default settings)</li>
<li>Ruby 1.9.3p194</li>
<li>ActiveRecord 3.2.6</li>
<li>an i5 760 with 4GB of RAM</li>
</ul>
<p>I have an &quot;items&quot; table with 15 columns (5 string, 5 integer, 1 text, 2 date and 2 float) and I&#39;m trying to add 100,000 items to the table.</p>
<p>Here are 4 different methods I&#39;ve tried:</p>
<p><strong>1. Plain ActiveRecord.create</strong>
Takes 262 seconds (2.62ms per item)</p>
<p><strong>2. Using the activerecord-import gem (using models)</strong>
Create an array with 100,000 items created using &quot;Item.new&quot; and then run &quot;Item.import items&quot;:</p>
<pre><code>  items = []  100_000.times { items &lt;&lt; Item.new(...) }  Item.import items
</code></pre><p>This technique takes 144 seconds (1.44ms per item) where the &quot;Item.new&quot; part takes 43.3 seconds and the &quot;Item.import&quot; part takes 100.7 seconds.</p>
<p>Improvement: <strong>~55% compared to plain activerecord</strong></p>
<p><strong>3. Using the activerecord-import gem (using arrays)</strong>
Instead of creating models, just create an array of arrays:</p>
<pre><code>  fields = %w{col1 col2 col3 ...}  items = []  100_000.times { items &lt;&lt; [&#39;value1&#39;, &#39;value2&#39;, ...] }Item.import fields, items
</code></pre><p>This technique takes 54 seconds (0.54ms per item) where creating 100,000 arrays takes 0.22 seconds and the insert takes 53.8 seconds.</p>
<p>Improvement: <strong>~21% compared to plain activerecord</strong></p>
<p><strong>4. Using the PostgreSQL COPY sql command</strong>
This time I created a CSV file and imported it using SQL (the CSV file has to be on the server&#39;s file system).</p>
<pre><code>  File.open(&#39;/tmp/items.csv&#39;, &#39;w&#39;) do |f|    100_000.times do { f.write(...) }  end  ActiveRecord::Base.connection.execute(
</code></pre><pre><code>    &quot;COPY items FROM &#39;/tmp/items.csv&#39; csv;&quot;)
</code></pre><p>This technique takes 2.22 seconds, 0.84 seconds to create the CSV and 1.38 for the &quot;COPY&quot; command.</p>
<p>Improvement: <strong>~0.85% compared to plain activerecord</strong></p>
<p><strong>Summary</strong></p>
<table>
<thead>
<tr>
<th>Technique</th>
<th>Total time (seconds)</th>
<th>Time per item (millisec)</th>
<th>Improvement</th>
</tr>
</thead>
<tbody>
<tr>
<td>Plain ActiveRecord</td>
<td>262</td>
<td>2.62</td>
<td></td>
</tr>
<tr>
<td>activerecord-import (models)</td>
<td>144</td>
<td>1.44</td>
<td>55%</td>
</tr>
<tr>
<td>activerecord-import (arrays)</td>
<td>54</td>
<td>0.54</td>
<td>21%</td>
</tr>
<tr>
<td>COPY</td>
<td>2.23</td>
<td>0.02</td>
<td>0.85%</td>
</tr>
</tbody>
</table>
<p>You can see the code for this benchmark here: <a href="https://github.com/elentok/db-benchmarks/tree/master/psql_normaltable">https://github.com/elentok/db-benchmarks/tree/master/psql_normaltable</a></p>
<p>Hope you found this useful,
David.</p>
</div></div><style type="text/css">@import "/style.css";
@import url('https://fonts.googleapis.com/css?family=Open+Sans|Source+Code+Pro');</style></body></html>